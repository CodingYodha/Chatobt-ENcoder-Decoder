{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>dirt</th>\n",
       "      <th>humor</th>\n",
       "      <th>kwid</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was the Ethiopian baby crying?</td>\n",
       "      <td>He was having a mid-life crisis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0       What's the best anti diarrheal prescription?   \n",
       "1  What do you call a person who is outside a doo...   \n",
       "2  Which Star Trek character is a member of the m...   \n",
       "3  What's the difference between a bullet and a h...   \n",
       "4                 Why was the Ethiopian baby crying?   \n",
       "\n",
       "                            Answer  dirt  humor  \\\n",
       "0                 Mycheexarphlexin   0.0    0.2   \n",
       "1                             Matt   0.0    0.2   \n",
       "2               Jean-Luc Pickacard   0.0    0.2   \n",
       "3    A bullet doesn't miss Harambe   0.0    0.2   \n",
       "4  He was having a mid-life crisis   0.0    0.2   \n",
       "\n",
       "                                                kwid  meta  \n",
       "0  BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN   NaN  \n",
       "1                 PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT   NaN  \n",
       "2  STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...   NaN  \n",
       "3  DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...   NaN  \n",
       "4               ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\qajokes1.1.2.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75107 entries, 0 to 75106\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  75107 non-null  object\n",
      " 1   Answer    75107 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['kwid' , 'meta', 'dirt' , 'humor'])\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34061</th>\n",
       "      <td>Whatcha doin?</td>\n",
       "      <td>Papa would say, \"I'M MINDING MY OWN DAMN BUSIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>What do you call a sick russian?</td>\n",
       "      <td>A sicka blyat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59884</th>\n",
       "      <td>What does Popeye use to toss his salad?</td>\n",
       "      <td>Olive Oil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61682</th>\n",
       "      <td>Why does the murder no longer use axe?</td>\n",
       "      <td>Because he realized it can't wash away his sins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40403</th>\n",
       "      <td>What's common to the cockpit of a modern fight...</td>\n",
       "      <td>The heads-up display</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "34061                                      Whatcha doin?   \n",
       "3952                    What do you call a sick russian?   \n",
       "59884            What does Popeye use to toss his salad?   \n",
       "61682             Why does the murder no longer use axe?   \n",
       "40403  What's common to the cockpit of a modern fight...   \n",
       "\n",
       "                                                  Answer  \n",
       "34061  Papa would say, \"I'M MINDING MY OWN DAMN BUSIN...  \n",
       "3952                                       A sicka blyat  \n",
       "59884                                         Olive Oil.  \n",
       "61682    Because he realized it can't wash away his sins  \n",
       "40403                               The heads-up display  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221282 entries, 0 to 221281\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   questions  221282 non-null  object\n",
      " 1   answers    221282 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#combine convokit dataset also\n",
    "df2 = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\Convokit_dataset.csv\")\n",
    "df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I told him I wouldn't - uh - go there an...</td>\n",
       "      <td>What am I supposed to say?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know. I haven't decided yet.</td>\n",
       "      <td>Who's your partner?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why?</td>\n",
       "      <td>I don't think you trust anybody, do you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bet your sweet ass we are.</td>\n",
       "      <td>Joe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>But Elaine --</td>\n",
       "      <td>I don't want you to go anywhere until you have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Well, I told him I wouldn't - uh - go there an...   \n",
       "1               I don't know. I haven't decided yet.   \n",
       "2                                               Why?   \n",
       "3                         Bet your sweet ass we are.   \n",
       "4                                      But Elaine --   \n",
       "\n",
       "                                              Answer  \n",
       "0                         What am I supposed to say?  \n",
       "1                                Who's your partner?  \n",
       "2           I don't think you trust anybody, do you?  \n",
       "3                                               Joe.  \n",
       "4  I don't want you to go anywhere until you have...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatinating both datsets\n",
    "# Rename columns in df2 to match df\n",
    "df2 = df2.rename(columns={'questions': 'Question', 'answers': 'Answer'})\n",
    "\n",
    "# Concatenate both datasets\n",
    "dfn = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "dfn = dfn.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296389 entries, 0 to 296388\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   Question  296389 non-null  object\n",
      " 1   Answer    296389 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 #used for padding short sentences\n",
    "SOS_token = 1 #start of sentence token\n",
    "EOS_token = 2 #End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\" , SOS_token:\"SOS\", EOS_token:\"EOS\"}\n",
    "        self.num_words = 3 #count sos , eos , pad\n",
    "\n",
    "    def addSentence(self , sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self , word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word]=1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Define contractions dictionary\n",
    "good_prefixes = {\n",
    "    \"i'm\": \"i am\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "}\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = \" \".join([good_prefixes[word] if word in good_prefixes else word for word in s.split()])\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()    \n",
    "    return s\n",
    "\n",
    "# Read query / response pairs and return a voc object\n",
    "def readVocs(datafile , corpus_name):\n",
    "    print(\"Reading lines......\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile , encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    #split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('<CoSe')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc , pairs\n",
    "\n",
    "\n",
    "# Returns true iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "MAX_LENGTH = 15\n",
    "def filterPair(p):\n",
    "    #input sequences need to preserve the last word for EOS token \n",
    "    return len(p[0].split(' '))<MAX_LENGTH and len(p[1].split(' '))<MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "#using the functions defined above , return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name , datafile , save_dir):\n",
    "    print(\"Start preparing training data .... \")\n",
    "    voc , pairs = readVocs(datafile , corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words....\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words: \", voc.num_words)\n",
    "    return voc , pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batchwise input and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "PAD_token = 0  # used for padding short sentences\n",
    "SOS_token = 1  # start of sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "def indexesFromSentence(voc , sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l , fillvalue = PAD_token):\n",
    "    return list(itertools.zip_longest(*l , fillvalue = fillvalue))\n",
    "\n",
    "def binaryMatrix(l , value=PAD_token):\n",
    "    m = []\n",
    "    for i , seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# returns padded input sequence tensor and lengths \n",
    "def inputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , lengths\n",
    "\n",
    "# returns padded target sequence tensor, padding mask , and max target length\n",
    "def outputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , mask , max_target_len\n",
    "\n",
    "#returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        print(\"Input sentence-\",pair[0])\n",
    "        print(\"Output sentece-\",pair[1])\n",
    "        print(\"-----------------------\")\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs from dataframe...\n",
      "Building vocabulary...\n",
      "\n",
      "Testing with a small batch...\n",
      "Input sentence- well that is alright . . . alright . good . you will graduate in another year is not that right ? you know . . . i never finished college . i was a good student but i never finished . of course there was a war then .\n",
      "Output sentece- i am not hungry .\n",
      "-----------------------\n",
      "Input sentence- joe it is not love . it is like . it is real strong like . and i got your information . now get off my back !\n",
      "Output sentece- i ve got twenty hours left . i could die in here . and you re falling in love .\n",
      "-----------------------\n",
      "Input sentence- do you want us to call the cops and have them give you the boots ?\n",
      "Output sentece- come on you ! before we slap you down .\n",
      "-----------------------\n",
      "Input sentence- what is the difference between jesus and a picture of jesus ?\n",
      "Output sentece- it only takes one nail to hang up the picture .\n",
      "-----------------------\n",
      "Input sentence- plan ? what are you talking about ?\n",
      "Output sentece- i get it ! this is your old plan right ?\n",
      "-----------------------\n",
      "\n",
      "Batch information:\n",
      "Input shape: torch.Size([51, 5])\n",
      "Lengths: tensor([51, 29, 17, 13,  9])\n",
      "Output shape: torch.Size([21, 5])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create a vocabulary instance\n",
    "voc = Voc('test')\n",
    "\n",
    "# Create pairs from your existing dataframe and normalize them\n",
    "print(\"Creating pairs from dataframe...\")\n",
    "pairs = []\n",
    "for _, row in dfn.iterrows():\n",
    "    question = normalizeString(row['Question'])\n",
    "    answer = normalizeString(row['Answer'])\n",
    "    pairs.append([question, answer])\n",
    "\n",
    "# Build vocabulary from pairs\n",
    "print(\"Building vocabulary...\")\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "\n",
    "# Example for validation\n",
    "print(\"\\nTesting with a small batch...\")\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nBatch information:\")\n",
    "print(\"Input shape:\", input_variable.shape)\n",
    "print(\"Lengths:\", lengths)\n",
    "print(\"Output shape:\", target_variable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence- i i do not think you have herr director . not yet . i mean it is quite n of course i will show it to you immediately .\n",
      "Output sentece- oh ? have i seen it ?\n",
      "-----------------------\n",
      "Input sentence- excuse me missus . no time for the old in out i ve just come to read the meter . slide of bird s nest with eggs .\n",
      "Output sentece- good . what do you want ?\n",
      "-----------------------\n",
      "Input sentence- why cannot you use a the restroom at a beatles reunion concert ?\n",
      "Output sentece- because there is no john .\n",
      "-----------------------\n",
      "Input sentence- what does the secret service say when donald trump gets shot at ?\n",
      "Output sentece- donald ! duck !\n",
      "-----------------------\n",
      "Input sentence- why does sirius black get all the girls ?\n",
      "Output sentece- because he is a real dawg .\n",
      "-----------------------\n",
      "\n",
      "Input variable:\n",
      "input shape: torch.Size([30, 5])\n",
      "lengths: tensor([30, 29, 14, 14, 10])\n",
      "\n",
      "Target variable:\n",
      "Output shape: torch.Size([8, 5])\n",
      "mask shape: torch.Size([8, 5])\n",
      "max_target_len: 8\n"
     ]
    }
   ],
   "source": [
    "def filterPair(voc, pair):\n",
    "\t# Return True if all words in both sentences are in vocab\n",
    "\treturn all(word in voc.word2index for word in pair[0].split()) and \\\n",
    "\t\t   all(word in voc.word2index for word in pair[1].split())\n",
    "\n",
    "# Get valid pairs\n",
    "valid_pairs = [pair for pair in pairs if filterPair(voc, pair)]\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(valid_pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nInput variable:\")\n",
    "print(\"input shape:\", input_variable.shape)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"\\nTarget variable:\")\n",
    "print(\"Output shape:\", target_variable.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
