{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>dirt</th>\n",
       "      <th>humor</th>\n",
       "      <th>kwid</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was the Ethiopian baby crying?</td>\n",
       "      <td>He was having a mid-life crisis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0       What's the best anti diarrheal prescription?   \n",
       "1  What do you call a person who is outside a doo...   \n",
       "2  Which Star Trek character is a member of the m...   \n",
       "3  What's the difference between a bullet and a h...   \n",
       "4                 Why was the Ethiopian baby crying?   \n",
       "\n",
       "                            Answer  dirt  humor  \\\n",
       "0                 Mycheexarphlexin   0.0    0.2   \n",
       "1                             Matt   0.0    0.2   \n",
       "2               Jean-Luc Pickacard   0.0    0.2   \n",
       "3    A bullet doesn't miss Harambe   0.0    0.2   \n",
       "4  He was having a mid-life crisis   0.0    0.2   \n",
       "\n",
       "                                                kwid  meta  \n",
       "0  BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN   NaN  \n",
       "1                 PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT   NaN  \n",
       "2  STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...   NaN  \n",
       "3  DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...   NaN  \n",
       "4               ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\qajokes1.1.2.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75107 entries, 0 to 75106\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  75107 non-null  object\n",
      " 1   Answer    75107 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['kwid' , 'meta', 'dirt' , 'humor'])\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36485</th>\n",
       "      <td>How would you describe frankenstein's birth?</td>\n",
       "      <td>Shocking!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46953</th>\n",
       "      <td>Why couldn't the Soviet Union get anything done?</td>\n",
       "      <td>They were always either Russian or Stalin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57794</th>\n",
       "      <td>What do you call it when a homosexual asks a q...</td>\n",
       "      <td>A Query.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67802</th>\n",
       "      <td>What's the least popular documentary?</td>\n",
       "      <td>Jiro nightmares of assrape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29710</th>\n",
       "      <td>Why was the lizard's wife unsatisfied?</td>\n",
       "      <td>Her hubby had a reptile dysfunction.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "36485       How would you describe frankenstein's birth?   \n",
       "46953   Why couldn't the Soviet Union get anything done?   \n",
       "57794  What do you call it when a homosexual asks a q...   \n",
       "67802              What's the least popular documentary?   \n",
       "29710             Why was the lizard's wife unsatisfied?   \n",
       "\n",
       "                                           Answer  \n",
       "36485                                   Shocking!  \n",
       "46953  They were always either Russian or Stalin.  \n",
       "57794                                   A Query.   \n",
       "67802                  Jiro nightmares of assrape  \n",
       "29710        Her hubby had a reptile dysfunction.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221282 entries, 0 to 221281\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   questions  221282 non-null  object\n",
      " 1   answers    221282 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#combine convokit dataset also\n",
    "df2 = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\Convokit_dataset.csv\")\n",
    "df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm coming.</td>\n",
       "      <td>Hurry up and get dressed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why did sumo wrestlers start shaving their legs?</td>\n",
       "      <td>To stop getting confused as feminists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's brown and sticky?</td>\n",
       "      <td>Poo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh! I'm sorry! I'm sorry! What have you got fo...</td>\n",
       "      <td>Put it down, I said! It's nothing for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please wait till my husband gets home.</td>\n",
       "      <td>Why not?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                                        I'm coming.   \n",
       "1   Why did sumo wrestlers start shaving their legs?   \n",
       "2                           What's brown and sticky?   \n",
       "3  Oh! I'm sorry! I'm sorry! What have you got fo...   \n",
       "4             Please wait till my husband gets home.   \n",
       "\n",
       "                                       Answer  \n",
       "0                   Hurry up and get dressed.  \n",
       "1       To stop getting confused as feminists  \n",
       "2                                        Poo!  \n",
       "3  Put it down, I said! It's nothing for you.  \n",
       "4                                    Why not?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatinating both datsets\n",
    "# Rename columns in df2 to match df\n",
    "df2 = df2.rename(columns={'questions': 'Question', 'answers': 'Answer'})\n",
    "\n",
    "# Concatenate both datasets\n",
    "dfn = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "dfn = dfn.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296389 entries, 0 to 296388\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   Question  296389 non-null  object\n",
      " 1   Answer    296389 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 #used for padding short sentences\n",
    "SOS_token = 1 #start of sentence token\n",
    "EOS_token = 2 #End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\" , SOS_token:\"SOS\", EOS_token:\"EOS\"}\n",
    "        self.num_words = 3 #count sos , eos , pad\n",
    "\n",
    "    def addSentence(self , sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self , word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word]=1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Define contractions dictionary\n",
    "good_prefixes = {\n",
    "    \"i'm\": \"i am\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "}\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = \" \".join([good_prefixes[word] if word in good_prefixes else word for word in s.split()])\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()    \n",
    "    return s\n",
    "\n",
    "# Read query / response pairs and return a voc object\n",
    "def readVocs(datafile , corpus_name):\n",
    "    print(\"Reading lines......\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile , encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    #split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('<CoSe')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc , pairs\n",
    "\n",
    "\n",
    "# Returns true iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "MAX_LENGTH = 15\n",
    "def filterPair(p):\n",
    "    #input sequences need to preserve the last word for EOS token \n",
    "    return len(p[0].split(' '))<MAX_LENGTH and len(p[1].split(' '))<MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "#using the functions defined above , return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name , datafile , save_dir):\n",
    "    print(\"Start preparing training data .... \")\n",
    "    voc , pairs = readVocs(datafile , corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words....\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words: \", voc.num_words)\n",
    "    return voc , pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batchwise input and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "PAD_token = 0  # used for padding short sentences\n",
    "SOS_token = 1  # start of sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "def indexesFromSentence(voc , sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l , fillvalue = PAD_token):\n",
    "    return list(itertools.zip_longest(*l , fillvalue = fillvalue))\n",
    "\n",
    "def binaryMatrix(l , value=PAD_token):\n",
    "    m = []\n",
    "    for i , seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# returns padded input sequence tensor and lengths \n",
    "def inputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , lengths\n",
    "\n",
    "# returns padded target sequence tensor, padding mask , and max target length\n",
    "def outputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , mask , max_target_len\n",
    "\n",
    "#returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        print(\"Input sentence-\",pair[0])\n",
    "        print(\"Output sentece-\",pair[1])\n",
    "        print(\"-----------------------\")\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs from dataframe...\n",
      "Building vocabulary...\n",
      "\n",
      "Testing with a small batch...\n",
      "Input sentence- not often but it is possible . most people get scared when they see the shadow of their limits . they do not know how long the shadow really is . they do not know how far away the real limits are standing . . . they stop out of fear .\n",
      "Output sentece- . . .when you work with clients on machines do they sometimes just jump up a level or two ? do something they did not know they were capable of ?\n",
      "-----------------------\n",
      "Input sentence- enough to get to jersey . i will walk the rest of the way . i ve been sitting a long time . nice meeting you . it is been a trip .\n",
      "Output sentece- the bus ll pick you up over there . uh . . . you got enough bread for a ticket ?\n",
      "-----------------------\n",
      "Input sentence- you might say i am part of the landscape here . they call me ben kenobi .\n",
      "Output sentece- who are you anyway ?\n",
      "-----------------------\n",
      "Input sentence- what couldn t the lifeguard save the hippie ?\n",
      "Output sentece- he was to far outtttttttttt . . . . . . . . ha weeeeeeed .\n",
      "-----------------------\n",
      "Input sentence- what is a rastafarian s favorite country ?\n",
      "Output sentece- yemen\n",
      "-----------------------\n",
      "\n",
      "Batch information:\n",
      "Input shape: torch.Size([53, 5])\n",
      "Lengths: tensor([53, 34, 18, 10,  9])\n",
      "Output shape: torch.Size([32, 5])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create a vocabulary instance\n",
    "voc = Voc('test')\n",
    "\n",
    "# Create pairs from your existing dataframe and normalize them\n",
    "print(\"Creating pairs from dataframe...\")\n",
    "pairs = []\n",
    "for _, row in dfn.iterrows():\n",
    "    question = normalizeString(row['Question'])\n",
    "    answer = normalizeString(row['Answer'])\n",
    "    pairs.append([question, answer])\n",
    "\n",
    "# Build vocabulary from pairs\n",
    "print(\"Building vocabulary...\")\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "\n",
    "# Example for validation\n",
    "print(\"\\nTesting with a small batch...\")\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nBatch information:\")\n",
    "print(\"Input shape:\", input_variable.shape)\n",
    "print(\"Lengths:\", lengths)\n",
    "print(\"Output shape:\", target_variable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence- i still cannot believe they re sending you to the belt you of all people never meant to be born on a mission to discover the origin of life .\n",
      "Output sentece- a day or so .\n",
      "-----------------------\n",
      "Input sentence- look get down now you fucking drunk ! you bum !\n",
      "Output sentece- oh there you are honey . we were waiting for you . what happened ?\n",
      "-----------------------\n",
      "Input sentence- no it is not mr . dowd .\n",
      "Output sentece- or this is this a significant difference ?\n",
      "-----------------------\n",
      "Input sentence- he was at the campground yesterday .\n",
      "Output sentece- but you re sure ?\n",
      "-----------------------\n",
      "Input sentence- you tell me .\n",
      "Output sentece- not everything is imputed to memory . the most confidential stuff is kept top secret hard copy . why would the zero file be kept secret ?\n",
      "-----------------------\n",
      "\n",
      "Input variable:\n",
      "input shape: torch.Size([31, 5])\n",
      "lengths: tensor([31, 12,  9,  8,  5])\n",
      "\n",
      "Target variable:\n",
      "Output shape: torch.Size([28, 5])\n",
      "mask shape: torch.Size([28, 5])\n",
      "max_target_len: 28\n"
     ]
    }
   ],
   "source": [
    "def filterPair(voc, pair):\n",
    "\t# Return True if all words in both sentences are in vocab\n",
    "\treturn all(word in voc.word2index for word in pair[0].split()) and \\\n",
    "\t\t   all(word in voc.word2index for word in pair[1].split())\n",
    "\n",
    "# Get valid pairs\n",
    "valid_pairs = [pair for pair in pairs if filterPair(voc, pair)]\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(valid_pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nInput variable:\")\n",
    "print(\"input shape:\", input_variable.shape)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"\\nTarget variable:\")\n",
    "print(\"Output shape:\", target_variable.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self , hidden_size, embedding, n_layers=1,dropout=0):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "#Initialize GRU ; THE input_size and hidden_size params are both set to 'hidden_size'ArithmeticError\n",
    "#because our input size is a word embedding with number of features == hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size,n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths , hidden=None):\n",
    "        \n",
    "        #convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        print(f\"Shape after embedding: {embedded.shape}\")\n",
    "        \n",
    "        #pack padded batch of sequences for RNN modu;e\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        print(f\"Shape after packing: {packed.data.shape}\")\n",
    "        \n",
    "        #forward pass through GRU\n",
    "        outputs , hidden = self.gru(packed , hidden)\n",
    "        print(f\"Shape after GRU: {outputs.data.shape}\")\n",
    "        \n",
    "        #unpack padding\n",
    "        outputs , _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        print(f\"Shape after unpacking: {outputs.shape}\")\n",
    "        \n",
    "        #sum birectional GRU  outputs\n",
    "        outputs = outputs[:,:,:self.hidden_size]+outputs[:,:,self.hidden_size]+outputs[:,:,self.hidden_size:]\n",
    "        print(f\"Shape after summing bidirectional outputs: {outputs.shape}\")\n",
    "        \n",
    "        #return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
