{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>dirt</th>\n",
       "      <th>humor</th>\n",
       "      <th>kwid</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was the Ethiopian baby crying?</td>\n",
       "      <td>He was having a mid-life crisis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0       What's the best anti diarrheal prescription?   \n",
       "1  What do you call a person who is outside a doo...   \n",
       "2  Which Star Trek character is a member of the m...   \n",
       "3  What's the difference between a bullet and a h...   \n",
       "4                 Why was the Ethiopian baby crying?   \n",
       "\n",
       "                            Answer  dirt  humor  \\\n",
       "0                 Mycheexarphlexin   0.0    0.2   \n",
       "1                             Matt   0.0    0.2   \n",
       "2               Jean-Luc Pickacard   0.0    0.2   \n",
       "3    A bullet doesn't miss Harambe   0.0    0.2   \n",
       "4  He was having a mid-life crisis   0.0    0.2   \n",
       "\n",
       "                                                kwid  meta  \n",
       "0  BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN   NaN  \n",
       "1                 PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT   NaN  \n",
       "2  STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...   NaN  \n",
       "3  DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...   NaN  \n",
       "4               ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\qajokes1.1.2.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75107 entries, 0 to 75106\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  75107 non-null  object\n",
      " 1   Answer    75107 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['kwid' , 'meta', 'dirt' , 'humor'])\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41819</th>\n",
       "      <td>What do you do if you're attacked by a bunch o...</td>\n",
       "      <td>Go for the Jugular (juggler)!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22310</th>\n",
       "      <td>Why is owning a Prius difficult?</td>\n",
       "      <td>It's hard to drive when you're patting yoursel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23309</th>\n",
       "      <td>Why did the jellybean go to  school?</td>\n",
       "      <td>A. Because he wanted to be a smarty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33058</th>\n",
       "      <td>Who's there ! Bunny ! Bunny who ?</td>\n",
       "      <td>Bunny thing is I've forgotten now !kn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>Why wasn't the joke funny at the dance?</td>\n",
       "      <td>There wasn't a punch line.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "41819  What do you do if you're attacked by a bunch o...   \n",
       "22310                   Why is owning a Prius difficult?   \n",
       "23309               Why did the jellybean go to  school?   \n",
       "33058                  Who's there ! Bunny ! Bunny who ?   \n",
       "2115             Why wasn't the joke funny at the dance?   \n",
       "\n",
       "                                                  Answer  \n",
       "41819                      Go for the Jugular (juggler)!  \n",
       "22310  It's hard to drive when you're patting yoursel...  \n",
       "23309                A. Because he wanted to be a smarty  \n",
       "33058              Bunny thing is I've forgotten now !kn  \n",
       "2115                          There wasn't a punch line.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221282 entries, 0 to 221281\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   questions  221282 non-null  object\n",
      " 1   answers    221282 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#combine convokit dataset also\n",
    "df2 = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\Convokit_dataset.csv\")\n",
    "df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the difference between Navy SEAL traini...</td>\n",
       "      <td>read aloud) One is six months of hell with a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate waiting. I could give you my word as a ...</td>\n",
       "      <td>That's very comforting. But I'm afraid you'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goodbye, Betty.</td>\n",
       "      <td>Not sometimes.  Always.  Just because it is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does an Indian kid say before leaving his...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't understand...</td>\n",
       "      <td>I belong here.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  What's the difference between Navy SEAL traini...   \n",
       "1  I hate waiting. I could give you my word as a ...   \n",
       "2                                    Goodbye, Betty.   \n",
       "3  What does an Indian kid say before leaving his...   \n",
       "4                              I don't understand...   \n",
       "\n",
       "                                              Answer  \n",
       "0  read aloud) One is six months of hell with a t...  \n",
       "1  That's very comforting. But I'm afraid you'll ...  \n",
       "2  Not sometimes.  Always.  Just because it is th...  \n",
       "3                                             Mumbai  \n",
       "4                                     I belong here.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatinating both datsets\n",
    "# Rename columns in df2 to match df\n",
    "df2 = df2.rename(columns={'questions': 'Question', 'answers': 'Answer'})\n",
    "\n",
    "# Concatenate both datasets\n",
    "dfn = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "dfn = dfn.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296389 entries, 0 to 296388\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   Question  296389 non-null  object\n",
      " 1   Answer    296389 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 #used for padding short sentences\n",
    "SOS_token = 1 #start of sentence token\n",
    "EOS_token = 2 #End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\" , SOS_token:\"SOS\", EOS_token:\"EOS\"}\n",
    "        self.num_words = 3 #count sos , eos , pad\n",
    "\n",
    "    def addSentence(self , sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self , word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word]=1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Define contractions dictionary\n",
    "good_prefixes = {\n",
    "    \"i'm\": \"i am\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "}\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = \" \".join([good_prefixes[word] if word in good_prefixes else word for word in s.split()])\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()    \n",
    "    return s\n",
    "\n",
    "# Read query / response pairs and return a voc object\n",
    "def readVocs(datafile , corpus_name):\n",
    "    print(\"Reading lines......\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile , encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    #split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('<CoSe')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc , pairs\n",
    "\n",
    "\n",
    "# Returns true iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "MAX_LENGTH = 15\n",
    "def filterPair(p):\n",
    "    #input sequences need to preserve the last word for EOS token \n",
    "    return len(p[0].split(' '))<MAX_LENGTH and len(p[1].split(' '))<MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "#using the functions defined above , return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name , datafile , save_dir):\n",
    "    print(\"Start preparing training data .... \")\n",
    "    voc , pairs = readVocs(datafile , corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words....\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words: \", voc.num_words)\n",
    "    return voc , pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batchwise input and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "PAD_token = 0  # used for padding short sentences\n",
    "SOS_token = 1  # start of sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "def indexesFromSentence(voc , sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l , fillvalue = PAD_token):\n",
    "    return list(itertools.zip_longest(*l , fillvalue = fillvalue))\n",
    "\n",
    "def binaryMatrix(l , value=PAD_token):\n",
    "    m = []\n",
    "    for i , seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# returns padded input sequence tensor and lengths \n",
    "def inputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , lengths\n",
    "\n",
    "# returns padded target sequence tensor, padding mask , and max target length\n",
    "def outputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , mask , max_target_len\n",
    "\n",
    "#returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        print(\"Input sentence-\",pair[0])\n",
    "        print(\"Output sentece-\",pair[1])\n",
    "        print(\"-----------------------\")\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs from dataframe...\n",
      "Building vocabulary...\n",
      "\n",
      "Testing with a small batch...\n",
      "Input sentence- we re thinking of doing this current affairs thing for schools . world history since . twelve programmes lots of stock film .\n",
      "Output sentece- and you re so beautiful . what are you doing here ?\n",
      "-----------------------\n",
      "Input sentence- a ha ! you landed on candyland ! now swallow it !\n",
      "Output sentece- if he heard you talking like that he d make you walk the plank . three two one . now it is your turn spin .\n",
      "-----------------------\n",
      "Input sentence- why do mules not work as hard as horses ?\n",
      "Output sentece- because they re half assed !\n",
      "-----------------------\n",
      "Input sentence- what drink can wrongly convict a black man ?\n",
      "Output sentece- tequila mockingbird\n",
      "-----------------------\n",
      "Input sentence- there s not much room\n",
      "Output sentece- oh no honey i will do that . . .\n",
      "-----------------------\n",
      "\n",
      "Batch information:\n",
      "Input shape: torch.Size([24, 5])\n",
      "Lengths: tensor([24, 13, 11, 10,  6])\n",
      "Output shape: torch.Size([27, 5])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create a vocabulary instance\n",
    "voc = Voc('test')\n",
    "\n",
    "# Create pairs from your existing dataframe and normalize them\n",
    "print(\"Creating pairs from dataframe...\")\n",
    "pairs = []\n",
    "for _, row in dfn.iterrows():\n",
    "    question = normalizeString(row['Question'])\n",
    "    answer = normalizeString(row['Answer'])\n",
    "    pairs.append([question, answer])\n",
    "\n",
    "# Build vocabulary from pairs\n",
    "print(\"Building vocabulary...\")\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "\n",
    "# Example for validation\n",
    "print(\"\\nTesting with a small batch...\")\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nBatch information:\")\n",
    "print(\"Input shape:\", input_variable.shape)\n",
    "print(\"Lengths:\", lengths)\n",
    "print(\"Output shape:\", target_variable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence- how do i know this is not just some kind of you know seduction or something ?\n",
      "Output sentece- sometimes . when it is convenient .\n",
      "-----------------------\n",
      "Input sentence- he was a very wealthy man he looked after me since i was young .\n",
      "Output sentece- was he a relative ? or an intimate friend ?\n",
      "-----------------------\n",
      "Input sentence- where the music s playing and the ladies are . . .\n",
      "Output sentece- in the yellow room where the music s playing and the ladies are ?\n",
      "-----------------------\n",
      "Input sentence- why is it unjust to blame taxi drivers for cheating us ?\n",
      "Output sentece- we call them to take us in . from the project gutenberg ebook of the handbook of conundrums by edith b . ordway . so this is a century old joke .\n",
      "-----------------------\n",
      "Input sentence- what does he weigh ?\n",
      "Output sentece- meat hes a butcher .\n",
      "-----------------------\n",
      "\n",
      "Input variable:\n",
      "input shape: torch.Size([18, 5])\n",
      "lengths: tensor([18, 16, 13, 13,  6])\n",
      "\n",
      "Target variable:\n",
      "Output shape: torch.Size([33, 5])\n",
      "mask shape: torch.Size([33, 5])\n",
      "max_target_len: 33\n"
     ]
    }
   ],
   "source": [
    "def filterPair(voc, pair):\n",
    "\t# Return True if all words in both sentences are in vocab\n",
    "\treturn all(word in voc.word2index for word in pair[0].split()) and \\\n",
    "\t\t   all(word in voc.word2index for word in pair[1].split())\n",
    "\n",
    "# Get valid pairs\n",
    "valid_pairs = [pair for pair in pairs if filterPair(voc, pair)]\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(valid_pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nInput variable:\")\n",
    "print(\"input shape:\", input_variable.shape)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"\\nTarget variable:\")\n",
    "print(\"Output shape:\", target_variable.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self , hidden_size, embedding, n_layers=1,dropout=0):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "#Initialize GRU ; THE input_size and hidden_size params are both set to 'hidden_size'ArithmeticError\n",
    "#because our input size is a word embedding with number of features == hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size,n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths , hidden=None):\n",
    "        \n",
    "        #convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        print(f\"Shape after embedding: {embedded.shape}\")\n",
    "        \n",
    "        #pack padded batch of sequences for RNN modu;e\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        print(f\"Shape after packing: {packed.data.shape}\")\n",
    "        \n",
    "        #forward pass through GRU\n",
    "        outputs , hidden = self.gru(packed , hidden)\n",
    "        print(f\"Shape after GRU: {outputs.data.shape}\")\n",
    "        \n",
    "        #unpack padding\n",
    "        outputs , _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        print(f\"Shape after unpacking: {outputs.shape}\")\n",
    "        \n",
    "        #sum birectional GRU  outputs\n",
    "        outputs = outputs[:,:,:self.hidden_size]+outputs[:,:,self.hidden_size]+outputs[:,:,self.hidden_size:]\n",
    "        print(f\"Shape after summing bidirectional outputs: {outputs.shape}\")\n",
    "        \n",
    "        #return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention layer and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "# Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "# Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "# Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "# Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
