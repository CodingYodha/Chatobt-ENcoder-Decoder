{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>dirt</th>\n",
       "      <th>humor</th>\n",
       "      <th>kwid</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was the Ethiopian baby crying?</td>\n",
       "      <td>He was having a mid-life crisis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0       What's the best anti diarrheal prescription?   \n",
       "1  What do you call a person who is outside a doo...   \n",
       "2  Which Star Trek character is a member of the m...   \n",
       "3  What's the difference between a bullet and a h...   \n",
       "4                 Why was the Ethiopian baby crying?   \n",
       "\n",
       "                            Answer  dirt  humor  \\\n",
       "0                 Mycheexarphlexin   0.0    0.2   \n",
       "1                             Matt   0.0    0.2   \n",
       "2               Jean-Luc Pickacard   0.0    0.2   \n",
       "3    A bullet doesn't miss Harambe   0.0    0.2   \n",
       "4  He was having a mid-life crisis   0.0    0.2   \n",
       "\n",
       "                                                kwid  meta  \n",
       "0  BEST-ANTI-DIARRHEAL-PRESCRIPTION-MYCHEEXARPHLEXIN   NaN  \n",
       "1                 PERSON-OUTSIDE-DOOR-ARMS-LEGS-MATT   NaN  \n",
       "2  STAR-TREK-CHARACTER-MEMBER-MAGIC-CIRCLE-JEANLU...   NaN  \n",
       "3  DIFFERENCE-BULLET-HUMAN-BULLET-DOESNT-MISS-HAR...   NaN  \n",
       "4               ETHIOPIAN-BABY-CRYING-MIDLIFE-CRISIS   NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\qajokes1.1.2.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75107 entries, 0 to 75106\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  75107 non-null  object\n",
      " 1   Answer    75107 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['kwid' , 'meta', 'dirt' , 'humor'])\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29561</th>\n",
       "      <td>Why is there no life on Mars?</td>\n",
       "      <td>No WiFi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58362</th>\n",
       "      <td>What does a gay guy say when he can't remember?</td>\n",
       "      <td>I faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71491</th>\n",
       "      <td>Who let the dogs out?</td>\n",
       "      <td>Chuck Norris let the dogs out...... and then r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64865</th>\n",
       "      <td>What did the Indian man name his sandwich shop?</td>\n",
       "      <td>New Delhi :D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39677</th>\n",
       "      <td>What do you call it when an Italian has one ar...</td>\n",
       "      <td>A speech impediment.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "29561                      Why is there no life on Mars?   \n",
       "58362    What does a gay guy say when he can't remember?   \n",
       "71491                              Who let the dogs out?   \n",
       "64865    What did the Indian man name his sandwich shop?   \n",
       "39677  What do you call it when an Italian has one ar...   \n",
       "\n",
       "                                                  Answer  \n",
       "29561                                         No WiFi...  \n",
       "58362                                           I faggot  \n",
       "71491  Chuck Norris let the dogs out...... and then r...  \n",
       "64865                                       New Delhi :D  \n",
       "39677                               A speech impediment.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221282 entries, 0 to 221281\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   questions  221282 non-null  object\n",
      " 1   answers    221282 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#combine convokit dataset also\n",
    "df2 = pd.read_csv(r\"E:\\Projects\\encoder - Decoder - chatbot\\Convokit_dataset.csv\")\n",
    "df2 = df2.drop(columns=['Unnamed: 0'])\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOM!</td>\n",
       "      <td>Make that sixty and I'm docking your allowance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name's Otis.</td>\n",
       "      <td>I know you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That was your idea, I wanted to...</td>\n",
       "      <td>Shit, Kid, you pulled your pistol... right out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Because - monster as I was - I was bound by La...</td>\n",
       "      <td>Kirsty Cotton.  Yes.  But ... if your soul was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Know about it? You think the Board would do an...</td>\n",
       "      <td>You mean you know about this?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                                               MOM!   \n",
       "1                                       Name's Otis.   \n",
       "2                 That was your idea, I wanted to...   \n",
       "3  Because - monster as I was - I was bound by La...   \n",
       "4  Know about it? You think the Board would do an...   \n",
       "\n",
       "                                              Answer  \n",
       "0  Make that sixty and I'm docking your allowance...  \n",
       "1                                        I know you?  \n",
       "2  Shit, Kid, you pulled your pistol... right out...  \n",
       "3  Kirsty Cotton.  Yes.  But ... if your soul was...  \n",
       "4                      You mean you know about this?  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatinating both datsets\n",
    "# Rename columns in df2 to match df\n",
    "df2 = df2.rename(columns={'questions': 'Question', 'answers': 'Answer'})\n",
    "\n",
    "# Concatenate both datasets\n",
    "dfn = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "dfn = dfn.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296389 entries, 0 to 296388\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   Question  296389 non-null  object\n",
      " 1   Answer    296389 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 #used for padding short sentences\n",
    "SOS_token = 1 #start of sentence token\n",
    "EOS_token = 2 #End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\" , SOS_token:\"SOS\", EOS_token:\"EOS\"}\n",
    "        self.num_words = 3 #count sos , eos , pad\n",
    "\n",
    "    def addSentence(self , sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self , word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word]=1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Define contractions dictionary\n",
    "good_prefixes = {\n",
    "    \"i'm\": \"i am\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "}\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = \" \".join([good_prefixes[word] if word in good_prefixes else word for word in s.split()])\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()    \n",
    "    return s\n",
    "\n",
    "# Read query / response pairs and return a voc object\n",
    "def readVocs(datafile , corpus_name):\n",
    "    print(\"Reading lines......\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile , encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    #split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('<CoSe')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc , pairs\n",
    "\n",
    "\n",
    "# Returns true iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "MAX_LENGTH = 15\n",
    "def filterPair(p):\n",
    "    #input sequences need to preserve the last word for EOS token \n",
    "    return len(p[0].split(' '))<MAX_LENGTH and len(p[1].split(' '))<MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "#using the functions defined above , return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name , datafile , save_dir):\n",
    "    print(\"Start preparing training data .... \")\n",
    "    voc , pairs = readVocs(datafile , corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words....\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words: \", voc.num_words)\n",
    "    return voc , pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batchwise input and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "PAD_token = 0  # used for padding short sentences\n",
    "SOS_token = 1  # start of sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "def indexesFromSentence(voc , sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l , fillvalue = PAD_token):\n",
    "    return list(itertools.zip_longest(*l , fillvalue = fillvalue))\n",
    "\n",
    "def binaryMatrix(l , value=PAD_token):\n",
    "    m = []\n",
    "    for i , seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# returns padded input sequence tensor and lengths \n",
    "def inputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , lengths\n",
    "\n",
    "# returns padded target sequence tensor, padding mask , and max target length\n",
    "def outputVar(l , voc):\n",
    "    indexes_batch = [indexesFromSentence(voc , sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar , mask , max_target_len\n",
    "\n",
    "#returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        print(\"Input sentence-\",pair[0])\n",
    "        print(\"Output sentece-\",pair[1])\n",
    "        print(\"-----------------------\")\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs from dataframe...\n",
      "Building vocabulary...\n",
      "\n",
      "Testing with a small batch...\n",
      "Input sentence- good . you ve got the only truck in the valley that can make it up that damn jeep trail . so here s the plan you and heather go for help . get to the mountains . . .\n",
      "Output sentece- no problem .\n",
      "-----------------------\n",
      "Input sentence- probably safe in the hands of the federal government .\n",
      "Output sentece- alright . . . turn around . she does not get shit unless i get that money . where is it ?\n",
      "-----------------------\n",
      "Input sentence- what is the difference between camping and being homeless ?\n",
      "Output sentece- marshmallows\n",
      "-----------------------\n",
      "Input sentence- do you know honduras johnny ?\n",
      "Output sentece- mr . san pedro sula is from honduras .\n",
      "-----------------------\n",
      "Input sentence- a computer canna lie sir .\n",
      "Output sentece- yet the data banks insist we fired twice . one computer is lying .\n",
      "-----------------------\n",
      "\n",
      "Batch information:\n",
      "Input shape: torch.Size([41, 5])\n",
      "Lengths: tensor([41, 11, 11,  7,  7])\n",
      "Output shape: torch.Size([23, 5])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create a vocabulary instance\n",
    "voc = Voc('test')\n",
    "\n",
    "# Create pairs from your existing dataframe and normalize them\n",
    "print(\"Creating pairs from dataframe...\")\n",
    "pairs = []\n",
    "for _, row in dfn.iterrows():\n",
    "    question = normalizeString(row['Question'])\n",
    "    answer = normalizeString(row['Answer'])\n",
    "    pairs.append([question, answer])\n",
    "\n",
    "# Build vocabulary from pairs\n",
    "print(\"Building vocabulary...\")\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "\n",
    "# Example for validation\n",
    "print(\"\\nTesting with a small batch...\")\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nBatch information:\")\n",
    "print(\"Input shape:\", input_variable.shape)\n",
    "print(\"Lengths:\", lengths)\n",
    "print(\"Output shape:\", target_variable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence- ha ! what a load of crap . look at yourself caesar . you re a thug . you launder money for the mob . you rent women like you rented this apartment .\n",
      "Output sentece- i saved you .\n",
      "-----------------------\n",
      "Input sentence- naah i am done . got to be on shift in a couple hours . are not you going in ?\n",
      "Output sentece- have another one sounds like you need it .\n",
      "-----------------------\n",
      "Input sentence- what qualifies as a short stack of pancakes ?\n",
      "Output sentece- i mean . feet is relatively short right yes okay cool . then i just ate a short stack .\n",
      "-----------------------\n",
      "Input sentence- what do black men hear most after sex ?\n",
      "Output sentece- back to your cell inmate .\n",
      "-----------------------\n",
      "Input sentence- were you a drug addict ?\n",
      "Output sentece- no .\n",
      "-----------------------\n",
      "\n",
      "Input variable:\n",
      "input shape: torch.Size([35, 5])\n",
      "lengths: tensor([35, 22, 10, 10,  7])\n",
      "\n",
      "Target variable:\n",
      "Output shape: torch.Size([21, 5])\n",
      "mask shape: torch.Size([21, 5])\n",
      "max_target_len: 21\n"
     ]
    }
   ],
   "source": [
    "def filterPair(voc, pair):\n",
    "\t# Return True if all words in both sentences are in vocab\n",
    "\treturn all(word in voc.word2index for word in pair[0].split()) and \\\n",
    "\t\t   all(word in voc.word2index for word in pair[1].split())\n",
    "\n",
    "# Get valid pairs\n",
    "valid_pairs = [pair for pair in pairs if filterPair(voc, pair)]\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(valid_pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"\\nInput variable:\")\n",
    "print(\"input shape:\", input_variable.shape)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"\\nTarget variable:\")\n",
    "print(\"Output shape:\", target_variable.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self , hidden_size, embedding, n_layers=1,dropout=0):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "#Initialize GRU ; THE input_size and hidden_size params are both set to 'hidden_size'ArithmeticError\n",
    "#because our input size is a word embedding with number of features == hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size,hidden_size,n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths , hidden=None):\n",
    "        \n",
    "        #convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        print(f\"Shape after embedding: {embedded.shape}\")\n",
    "        \n",
    "        #pack padded batch of sequences for RNN modu;e\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        print(f\"Shape after packing: {packed.data.shape}\")\n",
    "        \n",
    "        #forward pass through GRU\n",
    "        outputs , hidden = self.gru(packed , hidden)\n",
    "        print(f\"Shape after GRU: {outputs.data.shape}\")\n",
    "        \n",
    "        #unpack padding\n",
    "        outputs , _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        print(f\"Shape after unpacking: {outputs.shape}\")\n",
    "        \n",
    "        #sum birectional GRU  outputs\n",
    "        outputs = outputs[:,:,:self.hidden_size]+outputs[:,:,self.hidden_size]+outputs[:,:,self.hidden_size:]\n",
    "        print(f\"Shape after summing bidirectional outputs: {outputs.shape}\")\n",
    "        \n",
    "        #return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention layer and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Luong attention layer\n",
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "# Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "# Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "# Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "# Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Model configuration\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set training device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN('dot', embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "\n",
    "# Use CUDA if available\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.9\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 50\n",
    "print_every = 100\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "# Set model name and directory for saving\n",
    "model_name = 'chatbot_model'\n",
    "corpus_name = 'cornell_movie_dialogs'\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "\n",
    "# Create save directory if it doesn't exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Set loadFilename to None as we're training from scratch\n",
    "loadFilename = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "               embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "               print_every, save_every, clip, corpus_name, loadFilename):\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                       for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                    decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(\n",
    "                iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if iteration % save_every == 0:\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(\n",
    "                encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n",
    "\n",
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder,\n",
    "          embedding, encoder_optimizer, decoder_optimizer, batch_size, clip):\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if teacher forcing should be used for this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    loss = 0\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_variable[t].view(1, -1)  # Next input is current target\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _, topi = decoder_output.topk(1)  # [64, 1]\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "\n",
    "    # Perform backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
